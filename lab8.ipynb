{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab 8\n",
    "## Data Structures & Algorithms\n",
    "### Thursday, 11 April 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Today\n",
    "* [Divide-and-conquer refresher](#divide)\n",
    "* [Examples](#examples)\n",
    "* [Exercises](#exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide-and-conquer refresher\n",
    "\n",
    "Divide-and-conquer algorithms are a class of algorithms that solve a problem by breaking it down into smaller subproblems, solving the subproblems recursively, and then combining their solutions to solve the original problem. The basic steps of a divide-and-conquer algorithm are:\n",
    "\n",
    "1. **Divide**: Break the problem into smaller, more manageable subproblems.\n",
    "2. **Conquer**: Solve the subproblems recursively.\n",
    "3. **Combine**: Merge the solutions of the subproblems to solve the original problem.\n",
    "\n",
    "### Examples\n",
    "\n",
    "You saw many examples for divide-and-conquer algorithms in the lecture, here is just a subselection of those:\n",
    "\n",
    "- **Merge Sort**: A sorting algorithm that divides the array into two halves, sorts each half recursively, and then merges the sorted halves.\n",
    "- **Quick Sort**: Another sorting algorithm that selects a pivot element, partitions the array around the pivot, and then sorts the subarrays recursively.\n",
    "- **Binary Search**: A searching algorithm that divides the sorted array in half at each step to find the target element.\n",
    "- **Strassen's Algorithm**: A matrix multiplication algorithm that divides matrices into smaller submatrices and combines their products efficiently.\n",
    "- **Karatsuba Multiplication**: A multiplication algorithm for two n-digit numbers which reduces the process to three multiplications of n/2-digit numbers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation: Bubble Sort\n",
    "\n",
    "Before we dive into divide-and-conquer algorithms, let's first consider a simple sorting algorithm: bubble sort.\n",
    "\n",
    "Idea: loop through the input array (from left to right) n times (n=length of array). In each pass, we swap two adjacent numbers if the first number is larger than the second. What will happen? After the first round, the largest number will be moved to the last place of the array. After the second round, the second largest number will be moved to the second last place, etc.\n",
    "\n",
    "Here's an example implementation of selection sort in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_sort_brute_force(arr):\n",
    "    \"\"\"\n",
    "    Bubble sort \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : a list of number\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    The list sorted in ascending order\n",
    "    \"\"\"\n",
    "    \n",
    "    arr_temp = list(arr)\n",
    "    n = len(arr_temp)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n - 1):\n",
    "            # Get the difference between two adjacent numbers\n",
    "            diff = arr_temp[j] - arr_temp[j + 1]\n",
    "            if diff > 0:\n",
    "                # Swap the two numbers\n",
    "                arr_temp[j], arr_temp[j + 1] = arr_temp[j + 1], arr_temp[j]               \n",
    "\n",
    "    return arr_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[3]\n",
      "[2, 3]\n",
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "arr_1 = []\n",
    "arr_2 = [3]\n",
    "arr_3 = [3, 2]\n",
    "arr_4 = [3, 2, 1, 4]\n",
    "\n",
    "print(bubble_sort_brute_force(arr_1))\n",
    "print(bubble_sort_brute_force(arr_2))\n",
    "print(bubble_sort_brute_force(arr_3))\n",
    "print(bubble_sort_brute_force(arr_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time complexity of bubble sort is $O(n^2)$ where $n$ is the number of elements in the array to be sorted. In the worst-case scenario, where the input array is in reverse order, bubble sort will need to make $n$ passes through the array, with each pass requiring $O(n)$ comparisons and swaps. Despite its simplicity, bubble sort is not efficient for sorting large arrays due to its quadratic time complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved bubble sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save on some operations: in the first round, the largest number will be moved to the last place of the array. So in the second round, we do not have to consider the last element in the array as it is the largest element that we moved there in the first round. In the third round, we can ignore the last two elements, and so on. In round $i$, we can ignore the last $i-1$ elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_sort_improved(arr):\n",
    "    \"\"\"\n",
    "    Bubble sort \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : a list of number\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    The list sorted in ascending order\n",
    "    \"\"\"\n",
    "    \n",
    "    arr_temp = list(arr)\n",
    "    n = len(arr_temp)\n",
    "    \n",
    "    for i in range(n):\n",
    "        # in the second loop, we are leaving out the last i-1 elements of the array\n",
    "        for j in range(n - i - 1):\n",
    "            # Get the difference between two adjacent numbers\n",
    "            diff = arr_temp[j] - arr_temp[j + 1]\n",
    "            if diff > 0:\n",
    "                # Swap the two numbers\n",
    "                arr_temp[j], arr_temp[j + 1] = arr_temp[j + 1], arr_temp[j]               \n",
    "\n",
    "    return arr_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this still has running time $O(n^2)$, but it will still be a bit faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Sort\n",
    "\n",
    "Merge sort is another sorting algorithm that follows the divide-and-conquer approach. It works by dividing the array into two halves, sorting each half recursively, and then merging the sorted halves:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "   <img src=\"images/mergesort_viz.png\" width=\"500px\" title=\"mergesort visualisation\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example implementation of merge sort in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sort(arr):\n",
    "    \"\"\"\n",
    "    Merge sort \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : a list of number\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    The list sorted in ascending order\n",
    "    \"\"\"\n",
    "    arr_temp = list(arr)\n",
    "    n = len(arr_temp)    \n",
    "    \n",
    "    if n > 1: \n",
    "        # Divide the list into two smaller ones\n",
    "        # The middle of the list\n",
    "        mid = n // 2 # using floor division (aka integer division)\n",
    "        # The left sublist\n",
    "        arr_temp_left = arr_temp[:mid] \n",
    "        # The right sublist\n",
    "        arr_temp_right = arr_temp[mid:]\n",
    "  \n",
    "        # Recursively call merge_sort to sort the two smaller lists\n",
    "        arr_temp_left = merge_sort(arr_temp_left)\n",
    "        arr_temp_right = merge_sort(arr_temp_right)\n",
    "          \n",
    "        # Merge the two sorted smaller lists\n",
    "        i = j = k = 0\n",
    "        n_left, n_right = len(arr_temp_left), len(arr_temp_right)\n",
    "          \n",
    "        while i < n_left and j < n_right: \n",
    "            if arr_temp_left[i] < arr_temp_right[j]: \n",
    "                arr_temp[k] = arr_temp_left[i] \n",
    "                i += 1\n",
    "            else: \n",
    "                arr_temp[k] = arr_temp_right[j] \n",
    "                j += 1\n",
    "            k += 1\n",
    "          \n",
    "        # If there are elements in arr_temp_left that have not been visited \n",
    "        while i < n_left: \n",
    "            arr_temp[k] = arr_temp_left[i] \n",
    "            i += 1\n",
    "            k += 1\n",
    " \n",
    "        # If there are elements in arr_temp_right that have not been visited \n",
    "        while j < n_right: \n",
    "            arr_temp[k] = arr_temp_right[j] \n",
    "            j += 1\n",
    "            k += 1\n",
    "            \n",
    "    return arr_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[3]\n",
      "[2, 3]\n",
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "arr_1 = []\n",
    "arr_2 = [3]\n",
    "arr_3 = [3, 2]\n",
    "arr_4 = [3, 2, 1, 4]\n",
    "\n",
    "print(merge_sort(arr_1))\n",
    "print(merge_sort(arr_2))\n",
    "print(merge_sort(arr_3))\n",
    "print(merge_sort(arr_4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Time Complexity Analysis\n",
    "\n",
    "Merge sort has a time complexity of O(n log n) in all cases, making it a more efficient sorting algorithm than, for example, bubble sort. It achieves this time complexity by dividing the array into halves recursively and merging the sorted halves efficiently.\n",
    "\n",
    "Let's look at this in more detail: remember that for divide-and-conquer algorithms, we use a **recurrence relation** to express the running time. Let's say $T(n)$ is the worst-case running time of the algorithm for an input of size $n$, and at each step we subdivide the problem (in this case into two pieces of size $n/2$). At each step, we then know that the algorithm will spend $T(n/2)$ on each sub-problem plus some amount of time (in this case $O(n)$) on combining the subproblems. The running time of the algorithm therefore satisfies the recurrence relation:\n",
    "\n",
    "<div>\n",
    "   <img src=\"images/screenshot_mergesort.png\" width=\"300px\">\n",
    "</div>\n",
    "\n",
    "There are different ways of solving such a recurrence relation (i.e. make $T$ only appear on the left-hand side of the inequality). The most intuitive way is to 'unroll' the recurrence and look at patterns in the first few levels:\n",
    "\n",
    "<div>\n",
    "   <img src=\"images/screenshot_rectree_mergesort.png\" width=\"500px\">\n",
    "</div>\n",
    "What's going on here? At the top level, we're spennding $n$ iterations (or $cn$, but let's ignore the constant) on the combining part of the algorithm (plus the recursive calls). At the next level, we therefore spend - on each of the two subproblems time at most $n/2$. Since there are two of them, we are again at time $n$. Similarly for the next level. \n",
    "\n",
    "So at level $j$, the number of subproblems has doubled $j$ times, so there are now $2^j$ subproblems. Each has also got smaller by a factor of two $j$ times, so takes time at most $n/(2^j)$. This means that this level $j$ contributes $2^j (n/2^j) = n$ to the running time. Then we need to sum over all the levels. Since the number of times the input was halved to go from $n$ to $2$ is $\\log_2 n$ and we take $n$ at each level, the total running time is $O(n \\log n)$.\n",
    "\n",
    "Another way is to use the **Master Theorem**, which helps us analyse the runtime of these types of algorithms in a more general form. First, let's remind ourselves of the way in which the recurrence relation can be written more generally:\n",
    "\n",
    "<div>\n",
    "   <img src=\"images/screenshot_rec_equation.png\" width=\"600px\">\n",
    "</div>\n",
    "\n",
    "We can then establish the general form for the running time $T(n)$, following a similar pattern to the one we looked at for the recursion tree above. To get to the total running time, we have to sum up the time the algorithm spends at every level (and there are $\\log_b n$ levels), which depends on the number and the size of the subproblems (which is what makes up $r$). \n",
    "\n",
    "<div>\n",
    "   <img src=\"images/screenshot_mastertheorem.png\" width=\"500px\">\n",
    "</div>\n",
    "\n",
    "We can then use the this to infer whether an algorithm is root-dominated, leaf-dominated or balanced. For example, in the case where the combining step takes linear time ($c=1$) and dividing into subproblems of size $n/2$, then we have $r=a/2$. For different numbers of subproblems, we then have the following running times (based on the Master Theorem):\n",
    "\n",
    "* a = 1 - running time is linear\n",
    "* a = 2 - running time is O(n log n) (merge sort we looked at above)\n",
    "* a > 2 - running time is polynomial (bound with an exponent larger than 1 that grows with a).\n",
    "\n",
    "This is because the 'work' is spent on different parts of the recursion: when a = 1, the total running time is dominated by the top level (i.e. at the root, where it is spent on the combining element); when $a > 2$ the running time is dominated by the work done at the leaves (aka on the subproblems at the bottom of the recursion). This becomes clear when you look at the following two recursion trees in addition to the one for case $a=2$ that we saw above.\n",
    "\n",
    "For $a=3$, we have:\n",
    "<div>\n",
    "   <img src=\"images/screenshot_rectree_a3.png\" width=\"500px\">\n",
    "</div>\n",
    "\n",
    "For $a=1$, we have:\n",
    "<div>\n",
    "   <img src=\"images/screenshot_rectree_a1.png\" width=\"200px\">\n",
    "</div>\n",
    "\n",
    "(All visualisations of recursive trees are taken from the Kleinberg textbook, which also has great further explanations in it!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Extend the bubble sort algorithm from above, to make it even more efficient. \n",
    "\n",
    "When we pass an already sorted array to the implementation of the algorithm above, it always goes through the array $n$ times, which is unnecessary. In this even further improved version, we want to make sure that after each round of passing through the array, we first check if the array has already been sorted and we terminate the algorithm as soon as we find that it has. Implement this according to the following idea:\n",
    "\n",
    "* remember that we compare each two adjacent elements in the array and do a swap if the first is larger than the second\n",
    "* this means that if no two elements were swapped in a round, the array is already sorted!\n",
    "* include a variable in your code that indicates if any swap was made in a round\n",
    "* then terminate the algorithm once the flag variable has not recorded any swaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_sort_optimal(arr):\n",
    "    \"\"\"\n",
    "    Bubble sort \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : a list of number\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    The list sorted in ascending order\n",
    "    \"\"\"\n",
    "\n",
    "    # Implement me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Modify the merge sort algorithm to sort the elements in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sort_desc(arr):\n",
    "    \"\"\"\n",
    "    Merge sort in descending order\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : list\n",
    "        A list of numbers\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        The list sorted in descending order\n",
    "    \"\"\"\n",
    "    # Implement me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "As discussed in the lecture, an **inversion** in an array is when for two elements `array[i]` and `array[j]` we have `array[i]` > `array[j]` and `i < j`. E.g. `array = [3,1,2]` has two inversion: `(3,1)` and `(3,2)`. In other words, an inversion is every pair of elements that is violating an ascending order of the elements.\n",
    "\n",
    "Implement an algorithm for counting inversions in a naive way, where you go through every single pair of elements and check if it is an inversion. If it is, increase a counter by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_inversions_brute_force(arr):\n",
    "    \"\"\"\n",
    "    Count inversions in an array using the brute-force approach.\n",
    "    \n",
    "    Inversion in an array occurs when a pair of elements (arr[i], arr[j]) where i < j,\n",
    "    and arr[i] > arr[j].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : list\n",
    "        A list of numbers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The number of inversions in the array.\n",
    "    \"\"\"\n",
    "    # Implement me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "What is the time and space complexity of this algorithm? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Now, implement the counting inversions algorithm so that it runs in $O(n \\log n)$ using divide-and-conquer. In the end, it should return the total number of inversions and the sorted input array. Remember what you learnt about this in the lectures and read the very helpful section in the Algorithm Design (Kleinberg & Tardos) textbook (in chapter 5). The following hints for the implementations (and the solutions that will be provided) come from [this](https://www.geeksforgeeks.org/python-program-for-count-inversions-in-an-array-set-1-using-merge-sort/) website. Do try this yourself before looking at the implementation!\n",
    "\n",
    "* the idea of divide-and-conquer is always to recursively divide the array into subarrays\n",
    "* imagine that we divide an array into two subarrays and manage to find the number of inversions for each\n",
    "* to find the total number of inversions, we are then only missing the inversions that need to be counted across the two subarray (i.e. in the 'combination' or 'merge' step of the divide-and-conquer algorithm)\n",
    "* so the total number of inversions is the number of inversions in the left subarray, right subarray, and merge().\n",
    "* to get the number of inversions in merge(): let i is used for indexing left sub-array and j for right sub-array. At any step in merge(), if a[i] is greater than a[j], then there are (mid – i) inversions. because left and right subarrays are sorted, so all the remaining elements in left-subarray (a[i+1], a[i+2] … a[mid]) will be greater than a[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with the last part of the algorithm (counting the inversions in 'merge'), first write a merge-and-sort functions according to the following pseudo code from the Algorithm Design textbook. Note that this is a **very** similar algorithm to a part of the merge sort algorithm we looked at above (except you also have to keep track of the inversions as you merge the two arrays).\n",
    "\n",
    "```\n",
    "Merge-and-Count(A,B)\n",
    "    Maintain a Current pointer into each list, initialized to point to the front elements (e.g. use i and j, that are both 0 to start with)\n",
    "    Maintain a variable Count for the number of inversions, initialized to 0\n",
    "    While both lists are nonempty:\n",
    "        Let ai and bj be the elements pointed to by the Current pointers, ai = A[i] and bj = B[j]\n",
    "        Append the smaller of these two to the output list\n",
    "        If bj is the smaller element:\n",
    "            Increment Count by the number of elements remaining in A\n",
    "        Endif\n",
    "        Advance the Current pointer in the list from which the smaller element was selected.\n",
    "    EndWhile\n",
    "    Once one list is empty, append the remainder of the other list to the output\n",
    "    Return Count and the merged list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_count(A, B):\n",
    "    \"\"\"\n",
    "    Merge two sorted lists and count inversions\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : list\n",
    "        A sorted list.\n",
    "    B : list\n",
    "        Another sorted list.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    tuple\n",
    "        A tuple containing the merged sorted list and the number of inversions.\n",
    "    \"\"\"\n",
    "    # Implement me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "We now use the function written in the last exercise, to write the algorithm for counting inversions, that we call `sort_and_count`.\n",
    "\n",
    "Again, use the pseudo-code from the text book as a helper:\n",
    "\n",
    "```\n",
    "Sort-and-Count(L)\n",
    "If the list has one element:\n",
    "    there are no inversions\n",
    "Else\n",
    "    Divide the list into two halves:\n",
    "        A contains the first ⌈n/2⌉ elements\n",
    "        B contains the remaining ⌊n/2⌋ elements\n",
    "    (rA, A) = Sort-and-Count(A)\n",
    "    (rB, B) = Sort-and-Count(B)\n",
    "    (r,L) = Merge-and-Count(A,B)\n",
    "Endif\n",
    "Return r =rA +rB +r, and the sorted list L\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_and_count(L):\n",
    "    \"\"\"\n",
    "    Sort a list and count inversions using divide-and-conquer approach\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    L : list\n",
    "        A list of elements.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    tuple\n",
    "        A tuple containing the number of inversions and the sorted list.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Implement me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "Use the Master Theorem to give time complexity of the algorithm in Exercise 6 and say whether it is root-dominated, leaf-dominated or balanced."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
